{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Data Wrangling Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import tweepy\n",
    "#from tweepy import OAuthHandler\n",
    "#import json\n",
    "#from timeit import default_timer as timer\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "import twitter_credentials\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gathering Get Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "#if response.status_code == 200:\n",
    "#    print('Success!')\n",
    "#elif response.status_code == 404:\n",
    "#    print('Not Found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv('image_predictions.tsv', sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data manually with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('twitter_archive_enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering with the Twitter API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a quick assessment of the tweet_id column I saw a unique problem I would need to solve first before being able to gather my last dataset containing all of the twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.tweet_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering tweets from the twitter API requires precise id's and unfortunately my csv was imported with a column of **twitter_id** that my unique id had suffered some rounding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:.0f}'.format):  \n",
    "    print(df_1.tweet_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:.8f}'.format):  \n",
    "    print(df_1.tweet_id.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave me an oportunity to begin some data wrangling before jumping into the rest of my data. My solution to this issue was to split the strings of the URLs addresses that were included in the twitter_enhanced_archive csv file.  Using regular expression, I wanted to extract the Tweet Id's from the end of every URL. This required seperating the digits(these would be the id's I needed) from all of the char values that came before them, using '/' as a seperator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.expanded_urls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "My first step was to drop and null value in  **expanded_urls**, then take all of the remaining rows and place them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['expanded_urls'] = df_1.expanded_urls.fillna(value='https://www.twitter.com')\n",
    "urls = df_1.expanded_urls\n",
    "urls = list(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a new empty list, **status**, and used a loop to extract the id's from **urls**, appending\n",
    "each id to **status**. As a conditional, also appended the string '0' to status, every time my search\n",
    "was unable to find an accurate tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status= []\n",
    "for i in range(len(urls)): \n",
    "    t= urls[i]\n",
    "    if bool(re.search(r'\\d', t)) == True:\n",
    "        twt = re.findall(r'\\d+', t)[0]\n",
    "        status.append(twt)\n",
    "    else:\n",
    "        status.append('0')\n",
    "status[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I replaced my DataFrame column **tweet_id** with the values in **status** then removed all the values\n",
    "that contained the string '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['tweet_id'] = status\n",
    "df_1 = df_1.query(\"tweet_id != '0'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My last step was to change the data type of **tweet_id** from strings to the int64 data type, standardizing the **tweet_id** data type accross various sources of data to be able to merge in the future, and preparing them for my next gathering step of the Twitter API. Additionally, int64 also is the most efficient way to store values of unique digits, as integers require much less memory than a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.astype({'tweet_id':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = df_1['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "#count = 0\n",
    "#fails_dict = {}\n",
    "#start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "#with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "#    for tweet_id in tweet_ids:\n",
    "#        count += 1\n",
    "#        print(str(count) + \": \" + str(tweet_id))\n",
    "#        try:\n",
    "#            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#            print(\"Success\")\n",
    "#            json.dump(tweet._json, outfile)\n",
    "#            outfile.write('\\n')\n",
    "#        except tweepy.TweepError as e:\n",
    "#            print(\"Fail\")\n",
    "#            fails_dict[tweet_id] = e\n",
    "            \n",
    "#            pass\n",
    "#end = timer()\n",
    "#print(end - start)\n",
    "#print(fails_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2 = pd.DataFrame(columns=['tweet_id','retweet count','favorite_count'])\n",
    "\n",
    "#with open('tweet_json.txt') as i:\n",
    "#    for line in i:\n",
    "#        stat = json.loads(line)\n",
    "#        tweet_id = stat['id_str']\n",
    "#        retweet_count = stat['retweet_count']\n",
    "#        favorite_count = stat['favorite_count']\n",
    "#        df_2 = df_2.append(pd.DataFrame([[tweet_id,retweet_count,\n",
    "#                                         favorite_count]], \n",
    "#                                       columns=['tweet_id',\n",
    "#                                        'retweet_count', 'favorite_count']))\n",
    "#df_2 = df_2.reset_index(drop=True)\n",
    "#df_2.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2.to_csv (r'C:\\Users\\tssan\\Desktop\\Udacity Projects\\4wrangle\\WeRateDogs.csv',\n",
    "#                          index = None, header=True, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('WeRateDogs.csv', sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment\n",
    "### Visual Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_1.loc[:9].style.applymap(lambda x: 'color: red' if pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Five columns in the **df_1** Dataframe appear to contain missing values: \n",
    "    - **in_reply_to_status_id**, \n",
    "    - **in_reply_to_user_id**, \n",
    "    - **retweeed_status_id**, \n",
    "    - **retweeted_status_user_id**,  \n",
    "    - **retweeted_status_timestamp** \n",
    " \n",
    "- The **text** column contains the body of the tweet, but then ends each tweet with a hyperlink.  The hyperlink is already represented in the **expanded_urls** column, so having it shown twice is redundant information and is not really part of the text of the tweet. \n",
    "- The columns **doggo**, **floofer**, **pupper**, and **puppo** have the string \"None\" in many of there rows. These columns seem to be categorical varibales and would benefit by finding a melt them into a single categorical column.\n",
    "- The **timestamp** column is formatted down to the millisecond. This is accurate and thourough information, but for future timeseries analysis, I will convert the time in a date format of yyyy-MM-dd instead of the yyyy-MM-dd HH:mm:ss. SSS it is in now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images.loc[:10].style.applymap(lambda x: 'color: red' if pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The columns **p1**, **p2**, and **p3** are all in snake case format and some of the categorical values are capitalized while others are not.  To clean this up I would like to remove the underscore(s) of each row and put the classications in title format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.loc[:9].style.applymap(lambda x: 'color: red' if pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**retweet count** is an inconsistent format by not having an underscore to replace the space between words. By grouping column names in snake case the column names of a dataframe are callable. This would likely be a column name that I renamed to much python convention for a column name but it looks like it is a duplicate column to **reteet_count** and has a majority of NaN values. I will drop the column **retweet count** to tidy up the **df_2** DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programatic Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As observed above, five columns have missing values.\n",
    "    - **in_reply_to_status_id** and **in_reply_to_user_id** each have 2247 null values\n",
    "    - **retweeed_status_id**, **retweeted_status_user_id**, and **retweeted_status_timestamp** each have 2094 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After running a summary of the dataframe **df_2** we see that all 2166 values are missing in the column **retweet count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **images** dataframe has no missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_1.doggo.value_counts()\n",
    "b = df_1.floofer.value_counts()\n",
    "c = df_1.pupper.value_counts()\n",
    "d = df_1.puppo.value_counts()\n",
    "\n",
    "print(f'{a},\\n\\n{b},\\n\\n{c},\\n\\n{d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating_numerator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating_numerator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the cases if a numerator had a value\n",
    "greater than 14 it was only used once, however 75 occurs twice.\n",
    "I decided to look into this a little further to figure out why this was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1, ind2 = df_1.text[df_1.rating_numerator== 75].index.tolist()\n",
    "num = 75\n",
    "text1, text2 = df_1.text[ind1], df_1.text[ind2]\n",
    "print(f'Index: {ind1}\\nNumerator: {num}\\n{text1} \\n\\nIndex: {ind2}\\nNumerator: {num}\\n{text2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a closer look at these two tweets, I found two problems. The first is that the numerator is not 75, as it is listed in the df_1 dataset, its actually 10. The number 75 was misrepresented as the numerator in error when a rating of 9.75(a sneaky nod to the secret entrance of the Hogwarts Express on platform 9 and 3/4) was given to Logan and second, the indexed tweet #340 happens to be a duplicate of the indexed tweet #695 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.tweet_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming what we already knew from the previous cell, there are duplicates in the **df_1** dataset that will need to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.tweet_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.tweet_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the **df_1** dataset, duplicates were found in **df_2** as well. These duplicates will also need to be dropped. Luckily, no duplicates were found in the **images** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating_denominator.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating_denominator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.query('rating_denominator > 10').rating_denominator.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.query('rating_denominator < 10').rating_denominator.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2251 of the 2270 observations have a denominator of ten. I decided to look into this further to see if I could find out why this was. \n",
    "- 2 tweets have a denominator less than ten\n",
    "- 17 tweets have denominators greater than ten. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1, ind2 = df_1.text[df_1.rating_denominator < 10].index.tolist()\n",
    "denom1, denom2 = df_1.rating_denominator[ind1], df_1.rating_denominator[ind2]\n",
    "text1, text2 = df_1.text[ind1], df_1.text[ind2]\n",
    "print(f'Index: {ind1}\\nDenominator:{denom1}\\n{text1} \\n\\nIndex: {ind2} \\nDenominator:{denom2}\\n{text2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the the denominators that had values less then ten\n",
    "- Tweet indexed #516 was one few times where WeRateDogs was not given a rating.\n",
    "- Tweet indexed #2335 misrepresented the rating in error when a fraction of 1/2 was included in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df_1.query('rating_denominator > 10')['rating_denominator'].index.tolist()\n",
    "denom = df_1.query('rating_denominator > 10')['rating_denominator'].tolist()\n",
    "text = df_1.query('rating_denominator > 10')['text'].tolist()\n",
    "for i in range(len(ind)):\n",
    "    nex_ind = ind[i]\n",
    "    nex_denom = denom[i]\n",
    "    nex_text = text[i]\n",
    "    print(f'Index: {nex_ind}\\nDenominator: {nex_denom}\\n{nex_text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['timestamp'].min(), df_1['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.timestamp[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Assessment\n",
    "\n",
    "#### Quality issues\n",
    "**df_1** dataset\n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "\n",
    "**df_2** dataset\n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "\n",
    "**images** dataset\n",
    "- No quality errors were found in this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues\n",
    "**df_1** dataset \n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "\n",
    "**df_2** dataset\n",
    "- stuff\n",
    "- stuff\n",
    "- stuff\n",
    "\n",
    "**images** dataset\n",
    "- stuff\n",
    "- stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_clean = df_1.copy()\n",
    "df_2_clean = df_2.copy()\n",
    "images_clean = images.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 1. Dropping the columns with a majority of NaN values from the **df_1** dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.drop(columns=['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id',\n",
    "                   'retweeted_status_user_id','retweeted_status_timestamp'\n",
    "                   ], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 2. Melting Doggo, Pupper, Floofer, and Puppo down to one category variable named Cute_Name in the **df_1** Dataframe  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_1['doggo']\n",
    "b = df_1['pupper']\n",
    "c = df_1['floofer']\n",
    "d = df_1['puppo']\n",
    "\n",
    "\n",
    "df_1['cute_name'] = a.str.cat(b.replace('None','')).str.cat(c.replace('None','')).str.cat(d.replace('None',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dog = {'Nonefloofer':'floofer','Nonepupper':'pupper','Nonepuppo':'puppo','doggopupper':'doggo, pupper',\n",
    "           'doggofloofer':'doggo, floofer','doggopuppo':'doggo, puppo','None':'Other'}\n",
    "\n",
    "for key, value in dict_dog.items():\n",
    "    df_1['cute_name'] = df_1.cute_name.replace(key,value)\n",
    "    \n",
    "df_1.drop(columns=['doggo', 'floofer','pupper', 'puppo'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.cute_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 3.  Fixing Tweet 516 (No rating given) in the **df_1** Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.loc[516, 'rating_numerator']= np.median(df_1.rating_numerator)\n",
    "df_1.loc[516, 'rating_denominator']= np.median(df_1.rating_denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Since Sam was never given a rating, I gave him the median rating which is {df_1.loc[516,'rating_numerator']}/{df_1.loc[516,'rating_denominator']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 4.Dropping the duplicate in the **df_1** and **df_2** Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop_duplicates(subset=['tweet_id'],keep='first').reset_index()\n",
    "df_2 = df_2.drop_duplicates(subset=['tweet_id'],keep='first').reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_4. Test the results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.tweet_id.duplicated().any(), df_2.tweet_id.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 6. Dropping the 'source' column from **df** table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.drop(columns=['source'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i, row in df_1.iterrows():\n",
    "    if df_1.rating_denominator[i] != 10:\n",
    "        in_str= row['text']\n",
    "        try:\n",
    "            test = re.search(r'\\d+(?:\\.\\d+)?/10', in_str).group()\n",
    "            den = re.findall(r'\\d+', test)[1]\n",
    "            test = re.findall(r'\\d+', test)[0]\n",
    "            df_1.at[i,'rating_numerator'] = test\n",
    "            df_1.at[i,'rating_denominator'] = den\n",
    "            indices.append(i)\n",
    "        except:\n",
    "            test = 'Unchanged'\n",
    "        if test == 'Unchanged':\n",
    "            denominator = 'Unchanged'\n",
    "        else:\n",
    "            denominator = den\n",
    "                \n",
    "        print(f'Index: {i}\\nNumerator: {test}\\nDenominator: {denominator}\\n{in_str}\\n')\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    ind = indices[i]\n",
    "    num = df_1.rating_numerator[indices[i]]\n",
    "    den = df_1.rating_denominator[indices[i]]\n",
    "    print(f'Tweet #{ind} has a rating of {num}/{den}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 9. Normalizing Denominators to a Standard of 10 structuring data to facilitate analysis **df_1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_numerator= []\n",
    "norm_denominator= []\n",
    "for i, row in df_1.iterrows():\n",
    "    norm = 10 / row['rating_denominator']\n",
    "    num = row['rating_numerator'] = row['rating_numerator']* norm\n",
    "    norm_numerator.append(num)\n",
    "    den = row['rating_denominator'] = row['rating_denominator']* norm\n",
    "    norm_denominator.append(den)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['rating_numerator'] = norm_numerator\n",
    "df_1['rating_denominator'] = norm_denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.query('rating_denominator !=10')['rating_denominator'].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.drop(columns=['rating_denominator'],inplace = True)\n",
    "df_1.rename(columns={\"rating_numerator\": \"rating\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 12.  Correcting Ratings Containing Decimal Places, Using Regular Expression to loop through each text and pull out any digits with decimal places in **df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_1.iterrows():\n",
    "    in_str= row['text']\n",
    "    split = re.split(r'/' , in_str)[0]\n",
    "    if bool(re.search(r'\\d+\\.\\d+$', split)) == True:\n",
    "        after = re.findall(r'\\d+\\.\\d+', split)[0]\n",
    "        before = df_1.loc[i, 'rating']\n",
    "        df_1.loc[i, 'rating'] = after\n",
    "        print(f\"The rating in row {i} used to be {before} and now is {after}.\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No longer need the denominator columns, and the rating_numerator column\n",
    "#can just become rating (on a standardized scale of 10)\n",
    "df_1['rating'] = df_1['rating'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_1.rating\n",
    "text = df_1.text\n",
    "divide = \"---\" * 38\n",
    "\n",
    "for i in range(len(check)):\n",
    "    chk_dec = check[i]\n",
    "    txt = text[i] \n",
    "    if bool(chk_dec.is_integer()) == False:\n",
    "        print(f'Now row {i} has the correct rating of {chk_dec}. Take a look. \\n\\n{txt}\\n{divide}\\n')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 13. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding Ratings to get a discrete scale\n",
    "for i, row in df_1.iterrows():\n",
    "    before = df_1.loc[i, 'rating']\n",
    "    after = round(df_1.rating[i], 0)\n",
    "    df_1.loc[i, 'rating'] = after\n",
    "    if bool(before == after) == False :\n",
    "        print(f\"The rating in row {i} used to be {before} and now it is {after}.\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 14. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating = df_1.rating.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.rating.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['text'] = df_1.text.apply(lambda text: text.split('http')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = df_1.text[np.random.randint(0,len(df_1))]\n",
    "line2 = df_1.text[np.random.randint(0,len(df_1))]\n",
    "line3 = df_1.text[np.random.randint(0,len(df_1))]\n",
    "\n",
    "print(f'{line1}\\n\\n{line2} \\n\\n{line3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 5. Dropping columns with null data in the **df_2** Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(columns='retweet count', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 18. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['retweet_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['retweet_count'] = df_2['retweet_count'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images['p1'] = images['p1'].astype(str)\n",
    "\n",
    "def remove_snake(word):\n",
    "        return ''.join(x.lower() or '_' for x in word.replace('_', ' '))\n",
    "\n",
    "images['p1'] = images['p1'].apply(lambda x : remove_snake(x))\n",
    "images['p2'] = images['p2'].apply(lambda x : remove_snake(x))\n",
    "images['p3'] = images['p3'].apply(lambda x : remove_snake(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[['p1','p2','p3']].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 17. Merging **df_1**, **df_2**, and **images** Dataframes into a single table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.merge(df_2, on='tweet_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(images, on='tweet_id', how='inner').drop(columns=['index_x','index_y'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "- 18. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "try:\n",
    "    time = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['timestamp'] = time.dt.strftime('%Y/%m/%d %H:%M')\n",
    "    print('Success')\n",
    "except:\n",
    "    print('No changes made')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.timestamp.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv (r'~/Desktop/Udacity Projects/4wrangle/WeRateDogs_Clean.csv',\n",
    "                        #index = False, header=True, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cln = pd.read_csv('WeRateDogs_Clean.csv', sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln.groupby(['rating']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln[df_cln['rating'] == 420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln.text[1712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cln.jpg_url[1712])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At second place Snoop Dogg comes in at very impressive 420 out of 10\n",
    "<img src=\"second.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln[df_cln['rating'] == 1776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cln.text[757]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cln.jpg_url[757])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulation to the winner coming in at 1776 out of 10, such a good boy!\n",
    "<img src=\"winner.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Dog Ratings by Dog Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The two winners above are data points that were accurately gathered, but their ratings are also global outliers to the rest of the observations. These global outliers greatly increase the standard deviation of the variable **rating** in our DataFrame \n",
    "- To simplify our analysis, I decided to remove the two outliers, and take a deeper look into the distribution of the ratings by dog type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_before= df_cln.copy()\n",
    "df_after = df_cln[df_cln['rating'] < 15]\n",
    "\n",
    "#df_before= plots of the distribution of the data before and after removing the two outliers\n",
    "f, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "sns.boxplot(data=df_before,x= 'rating',orient='w', ax=axes[0])\n",
    "axes[0].set_title('Before, Including Global Outliers')\n",
    "\n",
    "\n",
    "sns.boxplot(data=df_after, x= 'rating',orient='w', ax=axes[1])\n",
    "axes[1].set_title('After, Excluding Global Outliers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate = df_after.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rate['p1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_types = df_rate['p1'].value_counts().keys()\n",
    "dog_types = list(dog_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_types = dog_types[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dog_types:\n",
    "    df_other = df_rate[(df_rate.p1 != d)]\n",
    "\n",
    "df_other = df_other.rating.value_counts().sort_index()\n",
    "df_other = df_other.rename_axis('rating').to_frame('other')\n",
    "\n",
    "for d in dog_types:\n",
    "    df_add = df_rate[df_rate['p1'] == d ]\n",
    "    df_add = df_add.rating.value_counts().sort_index()\n",
    "    df_add = df_add.rename_axis('rating').to_frame(d)\n",
    "    df_other = df_other.merge(df_add, on='rating',how='left').fillna(0)\n",
    "    \n",
    "\n",
    "df_other.loc[:,'Total'] = df_other.sum(axis=1)\n",
    "df_other.index = df_other.index.map(str)\n",
    "df_other.columns = [x.lower() for x in df_other.columns]\n",
    "df_all = df_other.copy()\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b='Black'\n",
    "r = df_all.index\n",
    "t = df_all.total\n",
    "c= sns.color_palette()[9]\n",
    "f_sz=12\n",
    "w='whitesmoke'\n",
    "fig = plt.figure(figsize=(6,7), facecolor=c)\n",
    "\n",
    "            \n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.barh(range(len(r)),t, color=w)\n",
    "plt.yticks(range(len(r)),r,fontsize=12, color=b)\n",
    "plt.ylabel('Rating',color=w,fontsize=f_sz)\n",
    "plt.xticks(color=b,fontsize=f_sz)\n",
    "plt.xlabel('Frequency',color=w,fontsize=f_sz)\n",
    "plt.title('Total Distribution of Dog Ratings',color='Black',fontsize=22)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(color='white', linestyle='dashed')\n",
    "plt.box(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "i = df_all.index\n",
    "t = df_all.total\n",
    "r = df_all.index\n",
    "ch = df_all.chihuahua\n",
    "g = df_all['golden retriever']\n",
    "l = df_all['labrador retriever']\n",
    "p = df_all.pembroke\n",
    "pu = df_all.pug\n",
    "ow = df_all.chow\n",
    "s = df_all.samoyed\n",
    "pm = df_all.pomeranian\n",
    "tp = df_all['toy poodle']\n",
    "c= sns.color_palette()[9]\n",
    "w='whitesmoke'\n",
    "b='Black'\n",
    "f_sz=16\n",
    "lim = [0,40]\n",
    "fig = plt.figure(figsize=(10,14), facecolor=c)\n",
    "grid = Grid(fig, rect=111, nrows_ncols=(2,2),\n",
    "            axes_pad=0.25, label_mode='L')\n",
    "\n",
    "\n",
    "\n",
    "ax1= plt.subplot(3, 3, 1)\n",
    "plt.barh(range(len(r)),g, color=w)\n",
    "plt.yticks(range(len(r)),r,fontsize=11,color=b)\n",
    "plt.xticks(color=b,fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.ylabel('Rating',color=w)\n",
    "plt.box(False)\n",
    "plt.title('Golden Retriever',fontsize=f_sz,color=b)\n",
    "plt.xlim(lim)\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax2= plt.subplot(3, 3, 2)\n",
    "plt.barh(range(len(r)),l, color=w)\n",
    "plt.yticks(range(len(r)),r)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Labrador',fontsize=f_sz,color=b)\n",
    "plt.xlim(lim)\n",
    "ax2.set_axisbelow(True)\n",
    "ax2.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "plt.barh(range(len(r)),ch, color=w)\n",
    "plt.yticks(range(len(r)),r)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax3.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Chihuah',fontsize=f_sz,color=b)\n",
    "plt.xlim(lim)\n",
    "ax3.set_axisbelow(True)\n",
    "ax3.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "plt.barh(range(len(r)),p, color=w)\n",
    "plt.yticks(range(len(r)),r,fontsize=11,color=b)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.ylabel('Rating',color=w)\n",
    "plt.box(False)\n",
    "plt.title('Pembroke',fontsize=f_sz,color=b)\n",
    "plt.xlim(lim)\n",
    "ax4.set_axisbelow(True)\n",
    "ax4.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "plt.barh(range(len(r)),pu, color=w)\n",
    "plt.yticks(range(len(r)),r)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax5.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Pug', fontsize=f_sz, color=b)\n",
    "plt.xlim(lim)\n",
    "ax5.set_axisbelow(True)\n",
    "ax5.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "plt.barh(range(len(r)),ow, color=w)\n",
    "plt.yticks(range(len(r)),r)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax6.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Chow', fontsize=f_sz, color=b)\n",
    "plt.xlim(lim)\n",
    "ax6.set_axisbelow(True)\n",
    "ax6.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "plt.barh(range(len(r)),ow, color=w)\n",
    "plt.yticks(range(len(r)),r,fontsize=11,color=b)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.ylabel('Rating',color=w)\n",
    "plt.setp(ax7.get_yticklabels(), visible=True)\n",
    "plt.box(False)\n",
    "plt.title('Samoyed', fontsize=f_sz, color=b)\n",
    "plt.xlim(lim)\n",
    "ax7.set_axisbelow(True)\n",
    "ax7.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "plt.barh(range(len(r)),pm, color=w)\n",
    "plt.yticks(range(len(r)),r,)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax8.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Pomeranian', fontsize=f_sz, color=b)\n",
    "plt.xlim(lim)\n",
    "ax8.set_axisbelow(True)\n",
    "ax8.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "plt.barh(range(len(r)),tp, color=w)\n",
    "plt.yticks(range(len(r)),r,)\n",
    "plt.xticks(color=b, fontsize=11)\n",
    "plt.xlabel('Frequency',color=w)\n",
    "plt.setp(ax9.get_yticklabels(), visible=False)\n",
    "plt.box(False)\n",
    "plt.title('Toy Poodle', fontsize=f_sz, color=b)\n",
    "plt.xlim(lim)\n",
    "ax9.set_axisbelow(True)\n",
    "ax9.yaxis.grid(color='white', linestyle='dashed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series of WeRateDogs Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_cln.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeries of Twitter Activity \n",
    "\n",
    "#Favorite and Retweet series\n",
    "time_faves = pd.Series(data=df_time['favorite_count'].values, index=df_time['timestamp']).sort_index(ascending=True)\n",
    "time_retweets = pd.Series(data=df_time['retweet_count'].values, index=df_time['timestamp']).sort_index(ascending=True)\n",
    "\n",
    "#Plotting both series to the same axis\n",
    "size= (12,8)\n",
    "\n",
    "time_faves.plot(kind='area',figsize=size, label='favorites',\n",
    "                color='deepskyblue',legend=True)\n",
    "time_retweets.plot(kind='area',figsize=size, label='retweet',\n",
    "                   color='crimson',legend=True)\n",
    "\n",
    "#Labels and preferences for the visualization\n",
    "\n",
    "plt.title('WeRateDogs Time Series of Favorites and Retweets',fontsize=18)\n",
    "plt.xlabel('Date',fontsize=18,color='crimson') \n",
    "plt.ylabel('Twitter Activity Count',fontsize=18, color='crimson')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(fontsize=14,frameon=False)\n",
    "\n",
    "\n",
    "plt.box(False)\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
